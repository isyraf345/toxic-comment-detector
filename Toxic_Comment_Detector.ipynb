{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gdt1W69QPSAo"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6dZ0xPDGNEui"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score, hamming_loss, f1_score\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import (\n",
        "    AutoTokenizer, AutoModelForSequenceClassification,\n",
        "    TrainingArguments, Trainer, EarlyStoppingCallback,\n",
        "    DataCollatorWithPadding\n",
        ")\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import gradio as gr\n",
        "import re\n",
        "import ftfy\n",
        "import io\n",
        "import os\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
        "import random"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3wc8YozvPKVa"
      },
      "source": [
        "**IMPORT THE DATASET**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "40PO_PTAbWOo"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v4xcHUNocBdc"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/toxic_comment_detector/train.csv')\n",
        "df.head(25)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rkIX3Ka_Ncmp"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vu2tQN1ROstb"
      },
      "source": [
        "**CLEANING THE DATASET**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w4rC-SwOOxYY"
      },
      "outputs": [],
      "source": [
        "#check missing values\n",
        "df.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9fgSflfdQ5pJ"
      },
      "outputs": [],
      "source": [
        "#Replace newlines, tabs, carriage returns with space\n",
        "df['comment_text'] = df['comment_text'].apply(lambda x: re.sub(r'[\\n\\r\\t]', ' ', x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iVPH-yNlgccU"
      },
      "outputs": [],
      "source": [
        "#Strip leading and trailing whitespace\n",
        "df['comment_text'] = df['comment_text'].apply(lambda x: x.strip())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "60sxieLsguwt"
      },
      "outputs": [],
      "source": [
        "#Remove excessive spaces\n",
        "df['comment_text'] = df['comment_text'].apply(lambda x: re.sub(r'\\s+', ' ', x))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PRImXbSmg6O-"
      },
      "outputs": [],
      "source": [
        "#Fix Encoding Artifacts (like â€™, Ã©)\n",
        "df['comment_text'] = df['comment_text'].apply(lambda x: ftfy.fix_text(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PXZqwQ9IhNnq"
      },
      "outputs": [],
      "source": [
        "excluded_cols = ['id', 'comment_text']\n",
        "\n",
        "for col in df.columns:\n",
        "    if col not in excluded_cols:\n",
        "        print(f\"\\nColumn: {col}\")\n",
        "        print(df[col].unique()) #print all value for labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "74vnan4okYKY"
      },
      "outputs": [],
      "source": [
        "df.head(30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5aip8ez0kike"
      },
      "source": [
        "**TRAIN THE MODELS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ab2o8-bWyZa"
      },
      "outputs": [],
      "source": [
        "# Set random seeds for reproducibility\n",
        "random.seed(42)\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "\n",
        "class ToxicDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_len=128, model_name=\"\"):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "        self.model_name = model_name.lower()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = str(self.texts[idx])\n",
        "\n",
        "        # Handle different tokenizer requirements\n",
        "        tokenizer_kwargs = {\n",
        "            'text': text,\n",
        "            'add_special_tokens': True,\n",
        "            'max_length': self.max_len,\n",
        "            'padding': 'max_length',\n",
        "            'truncation': True,\n",
        "            'return_attention_mask': True,\n",
        "            'return_tensors': 'pt'\n",
        "        }\n",
        "\n",
        "        # Only add token_type_ids for models that support it (not DistilBERT)\n",
        "        if 'distilbert' not in self.model_name:\n",
        "            tokenizer_kwargs['return_token_type_ids'] = True\n",
        "\n",
        "        inputs = self.tokenizer.encode_plus(**tokenizer_kwargs)\n",
        "\n",
        "        result = {\n",
        "            'input_ids': inputs['input_ids'].flatten(),\n",
        "            'attention_mask': inputs['attention_mask'].flatten(),\n",
        "            'labels': torch.FloatTensor(self.labels[idx])\n",
        "        }\n",
        "\n",
        "        # Add token_type_ids only if it exists in inputs\n",
        "        if 'token_type_ids' in inputs:\n",
        "            result['token_type_ids'] = inputs['token_type_ids'].flatten()\n",
        "\n",
        "        return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BgXTZslzXJd3"
      },
      "outputs": [],
      "source": [
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    predictions = torch.sigmoid(torch.tensor(predictions)).numpy()\n",
        "\n",
        "    # Convert to binary predictions\n",
        "    binary_predictions = (predictions > 0.5).astype(int)\n",
        "\n",
        "    # Calculate metrics\n",
        "    auc_scores = []\n",
        "    f1_scores = []\n",
        "\n",
        "    for i in range(labels.shape[1]):\n",
        "        if len(np.unique(labels[:, i])) > 1:  # Check if both classes exist\n",
        "            auc = roc_auc_score(labels[:, i], predictions[:, i])\n",
        "            auc_scores.append(auc)\n",
        "            f1 = f1_score(labels[:, i], binary_predictions[:, i])\n",
        "            f1_scores.append(f1)\n",
        "\n",
        "    return {\n",
        "        'auc': np.mean(auc_scores),\n",
        "        'f1': np.mean(f1_scores)\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XZP_axw2XOYK"
      },
      "outputs": [],
      "source": [
        "class ToxicCommentDetector:\n",
        "    def __init__(self):\n",
        "        self.models = {}\n",
        "        self.tokenizers = {}\n",
        "        self.label_columns = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
        "\n",
        "        # Model configurations optimized for Colab\n",
        "        self.model_configs = {\n",
        "            'DistilBERT': {\n",
        "                'name': 'distilbert-base-uncased',\n",
        "                'max_len': 128,\n",
        "                'batch_size': 16,\n",
        "                'epochs': 3,\n",
        "                'lr': 2e-5\n",
        "            },\n",
        "            'RoBERTa': {\n",
        "                'name': 'roberta-base',\n",
        "                'max_len': 128,\n",
        "                'batch_size': 8,\n",
        "                'epochs': 3,\n",
        "                'lr': 1e-5\n",
        "            },\n",
        "            'ALBERT': {\n",
        "                'name': 'albert-base-v2',\n",
        "                'max_len': 128,\n",
        "                'batch_size': 16,\n",
        "                'epochs': 3,\n",
        "                'lr': 3e-5\n",
        "            },\n",
        "            'electra-small': {\n",
        "                'name': 'google/electra-small-discriminator',\n",
        "                'max_len': 128,\n",
        "                'batch_size': 16,\n",
        "                'epochs': 3,\n",
        "                'lr': 2e-5\n",
        "            }\n",
        "        }\n",
        "\n",
        "    def load_and_preprocess_data(self, df):\n",
        "        \"\"\"Load and preprocess the dataset\"\"\"\n",
        "        print(\"📊 Dataset Overview:\")\n",
        "        print(f\"Total samples: {len(df)}\")\n",
        "        print(f\"Columns: {df.columns.tolist()}\")\n",
        "\n",
        "        # Check label distribution\n",
        "        print(\"\\n📈 Label Distribution:\")\n",
        "        for col in self.label_columns:\n",
        "            positive_ratio = df[col].mean()\n",
        "            print(f\"{col}: {positive_ratio:.3f} ({positive_ratio*100:.1f}% positive)\")\n",
        "\n",
        "        # Sample down for faster training (adjust based on your needs)\n",
        "        # Using stratified sampling to maintain label distribution\n",
        "        sample_size = min(50000, len(df))  # Adjust this based on your resources\n",
        "        if len(df) > sample_size:\n",
        "            print(f\"\\n🎯 Sampling {sample_size} examples for faster training...\")\n",
        "            df_sampled = df.sample(n=sample_size, random_state=42)\n",
        "        else:\n",
        "            df_sampled = df.copy()\n",
        "\n",
        "        # Split the data\n",
        "        X = df_sampled['comment_text'].values\n",
        "        y = df_sampled[self.label_columns].values\n",
        "\n",
        "        X_train, X_temp, y_train, y_temp = train_test_split(\n",
        "            X, y, test_size=0.3, random_state=42, stratify=y[:, 0]  # Stratify on toxic label\n",
        "        )\n",
        "\n",
        "        X_val, X_test, y_val, y_test = train_test_split(\n",
        "            X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp[:, 0]\n",
        "        )\n",
        "\n",
        "        print(f\"\\n📋 Data Split:\")\n",
        "        print(f\"Training: {len(X_train)} samples\")\n",
        "        print(f\"Validation: {len(X_val)} samples\")\n",
        "        print(f\"Testing: {len(X_test)} samples\")\n",
        "\n",
        "        return X_train, X_val, X_test, y_train, y_val, y_test\n",
        "\n",
        "    def train_model(self, model_name, X_train, X_val, y_train, y_val):\n",
        "        print(f\"\\n🚀 Training {model_name}...\")\n",
        "\n",
        "        config = self.model_configs[model_name]\n",
        "\n",
        "        # Load tokenizer and model\n",
        "        tokenizer = AutoTokenizer.from_pretrained(config['name'])\n",
        "        model = AutoModelForSequenceClassification.from_pretrained(\n",
        "            config['name'],\n",
        "            num_labels=len(self.label_columns),\n",
        "            problem_type=\"multi_label_classification\"\n",
        "        )\n",
        "\n",
        "        # Create datasets\n",
        "        train_dataset = ToxicDataset(X_train, y_train, tokenizer, config['max_len'], model_name)\n",
        "        val_dataset = ToxicDataset(X_val, y_val, tokenizer, config['max_len'], model_name)\n",
        "\n",
        "        # Training arguments with hyperparameter tuning\n",
        "        training_args = TrainingArguments(\n",
        "            output_dir=f'./results_{model_name.lower()}',\n",
        "            num_train_epochs=config['epochs'],\n",
        "            per_device_train_batch_size=config['batch_size'],\n",
        "            per_device_eval_batch_size=config['batch_size'],\n",
        "            warmup_steps=500,\n",
        "            weight_decay=0.01,\n",
        "            logging_dir=f'./logs_{model_name.lower()}',\n",
        "            logging_steps=100,\n",
        "            eval_strategy=\"steps\",\n",
        "            eval_steps=500,\n",
        "            save_strategy=\"steps\",\n",
        "            save_steps=500,\n",
        "            load_best_model_at_end=True,\n",
        "            metric_for_best_model=\"auc\",\n",
        "            greater_is_better=True,\n",
        "            learning_rate=config['lr'],\n",
        "            adam_epsilon=1e-8,\n",
        "            max_grad_norm=1.0,\n",
        "            fp16=True if torch.cuda.is_available() else False,\n",
        "            dataloader_num_workers=0,\n",
        "            save_total_limit=1,\n",
        "        )\n",
        "\n",
        "        # Initialize trainer\n",
        "        trainer = Trainer(\n",
        "            model=model,\n",
        "            args=training_args,\n",
        "            train_dataset=train_dataset,\n",
        "            eval_dataset=val_dataset,\n",
        "            compute_metrics=compute_metrics,\n",
        "            callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]\n",
        "        )\n",
        "\n",
        "        # Train the model\n",
        "        trainer.train()\n",
        "\n",
        "        # Save model and tokenizer\n",
        "        model_dir = f\"/content/drive/MyDrive/toxic comment detector/{model_name}\"\n",
        "        model.save_pretrained(model_dir)\n",
        "        tokenizer.save_pretrained(model_dir)\n",
        "        print(f\"📦 Model and tokenizer saved to {model_dir}\")\n",
        "\n",
        "        # Save references for later use\n",
        "        self.models[model_name] = model\n",
        "        self.tokenizers[model_name] = tokenizer\n",
        "\n",
        "        # Evaluate on validation set\n",
        "        eval_results = trainer.evaluate()\n",
        "        print(f\"✅ {model_name} - Validation AUC: {eval_results['eval_auc']:.4f}, F1: {eval_results['eval_f1']:.4f}\")\n",
        "\n",
        "        return eval_results\n",
        "\n",
        "\n",
        "    def predict(self, text, model_name):\n",
        "        \"\"\"Make predictions using a specific model\"\"\"\n",
        "        if model_name not in self.models:\n",
        "            raise ValueError(f\"Model {model_name} not trained yet!\")\n",
        "\n",
        "        model = self.models[model_name]\n",
        "        tokenizer = self.tokenizers[model_name]\n",
        "\n",
        "        # Check if model is on CUDA, if so move to CPU for prediction\n",
        "        device = next(model.parameters()).device\n",
        "\n",
        "        # Tokenize input - handle DistilBERT token_type_ids issue\n",
        "        tokenizer_kwargs = {\n",
        "            'text': text,\n",
        "            'add_special_tokens': True,\n",
        "            'max_length': 128,\n",
        "            'padding': 'max_length',\n",
        "            'truncation': True,\n",
        "            'return_attention_mask': True,\n",
        "            'return_tensors': 'pt'\n",
        "        }\n",
        "\n",
        "        # Only add token_type_ids for models that support it (not DistilBERT)\n",
        "        if 'distilbert' not in model_name.lower():\n",
        "            tokenizer_kwargs['return_token_type_ids'] = True\n",
        "\n",
        "        inputs = tokenizer.encode_plus(**tokenizer_kwargs)\n",
        "\n",
        "        # Move inputs to the same device as model\n",
        "        for key in inputs:\n",
        "            inputs[key] = inputs[key].to(device)\n",
        "\n",
        "        # Make prediction\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "            predictions = torch.sigmoid(outputs.logits).cpu().numpy()[0]\n",
        "\n",
        "        # Create results dictionary\n",
        "        results = {}\n",
        "        for i, label in enumerate(self.label_columns):\n",
        "            results[label] = float(predictions[i])\n",
        "\n",
        "        return results\n",
        "\n",
        "    def evaluate_all_models(self, X_test, y_test):\n",
        "        \"\"\"Evaluate all trained models on test set\"\"\"\n",
        "        results = {}\n",
        "\n",
        "        for model_name in self.models.keys():\n",
        "            print(f\"\\n🔍 Evaluating {model_name} on test set...\")\n",
        "\n",
        "            model = self.models[model_name]\n",
        "            tokenizer = self.tokenizers[model_name]\n",
        "\n",
        "            # Create test dataset\n",
        "            test_dataset = ToxicDataset(X_test, y_test, tokenizer, 128, model_name)\n",
        "\n",
        "            # Create trainer for evaluation\n",
        "            trainer = Trainer(\n",
        "                model=model,\n",
        "                compute_metrics=compute_metrics,\n",
        "            )\n",
        "\n",
        "            # Evaluate\n",
        "            eval_results = trainer.evaluate(test_dataset)\n",
        "            results[model_name] = {\n",
        "                'auc': eval_results['eval_auc'],\n",
        "                'f1': eval_results['eval_f1']\n",
        "            }\n",
        "\n",
        "            print(f\"📊 {model_name} - Test AUC: {eval_results['eval_auc']:.4f}, F1: {eval_results['eval_f1']:.4f}\")\n",
        "\n",
        "        return results"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Main training pipeline\n",
        "def train_toxic_detector(df):\n",
        "    \"\"\"Complete training pipeline\"\"\"\n",
        "    detector = ToxicCommentDetector()\n",
        "\n",
        "    # Load and preprocess data\n",
        "    X_train, X_val, X_test, y_train, y_val, y_test = detector.load_and_preprocess_data(df)\n",
        "\n",
        "    # Train all models\n",
        "    validation_results = {}\n",
        "    for model_name in detector.model_configs.keys():\n",
        "        try:\n",
        "            eval_results = detector.train_model(model_name, X_train, X_val, y_train, y_val)\n",
        "            validation_results[model_name] = eval_results\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Error training {model_name}: {str(e)}\")\n",
        "            continue\n",
        "\n",
        "    # Evaluate on test set\n",
        "    test_results = detector.evaluate_all_models(X_test, y_test)\n",
        "\n",
        "    # Print summary\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"📋 FINAL RESULTS SUMMARY\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    results_df = pd.DataFrame({\n",
        "        'Model': list(test_results.keys()),\n",
        "        'Test_AUC': [results['auc'] for results in test_results.values()],\n",
        "        'Test_F1': [results['f1'] for results in test_results.values()]\n",
        "    })\n",
        "\n",
        "    results_df = results_df.sort_values('Test_AUC', ascending=False)\n",
        "    print(results_df.to_string(index=False))\n",
        "\n",
        "    return detector, results_df"
      ],
      "metadata": {
        "id": "QGRr3PkWe8nd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Gradio Interface\n",
        "def create_gradio_interface(detector):\n",
        "    \"\"\"Create Gradio interface for the app\"\"\"\n",
        "\n",
        "    def predict_toxicity(text, model_name):\n",
        "        \"\"\"Predict toxicity for given text\"\"\"\n",
        "        if not text.strip():\n",
        "            return \"Please enter some text to analyze.\"\n",
        "\n",
        "        try:\n",
        "            results = detector.predict(text, model_name)\n",
        "\n",
        "            # Format results\n",
        "            output = f\"🔍 **Analysis Results using {model_name}:**\\n\\n\"\n",
        "            for label, score in results.items():\n",
        "                emoji = \"🚨\" if score > 0.5 else \"✅\"\n",
        "                output += f\"{emoji} **{label.replace('_', ' ').title()}**: {score:.3f} ({score*100:.1f}%)\\n\"\n",
        "\n",
        "            return output\n",
        "\n",
        "        except Exception as e:\n",
        "            return f\"Error: {str(e)}\"\n",
        "\n",
        "    def compare_models(text):\n",
        "        \"\"\"Compare all models for the same text\"\"\"\n",
        "        if not text.strip():\n",
        "            return \"Please enter some text to analyze.\", None\n",
        "\n",
        "        try:\n",
        "            all_results = {}\n",
        "            for model_name in detector.models.keys():\n",
        "                results = detector.predict(text, model_name)\n",
        "                all_results[model_name] = results\n",
        "\n",
        "            # Create comparison chart\n",
        "            fig, ax = plt.subplots(figsize=(12, 8))\n",
        "\n",
        "            models = list(all_results.keys())\n",
        "            labels = detector.label_columns\n",
        "            x = np.arange(len(labels))\n",
        "            width = 0.25\n",
        "\n",
        "            for i, model in enumerate(models):\n",
        "                scores = [all_results[model][label] for label in labels]\n",
        "                ax.bar(x + i*width, scores, width, label=model, alpha=0.8)\n",
        "\n",
        "            ax.set_xlabel('Toxicity Categories')\n",
        "            ax.set_ylabel('Probability Score')\n",
        "            ax.set_title(f'Model Comparison for: \"{text[:50]}...\"')\n",
        "            ax.set_xticks(x + width)\n",
        "            ax.set_xticklabels([label.replace('_', ' ').title() for label in labels], rotation=45)\n",
        "            ax.legend()\n",
        "            ax.grid(True, alpha=0.3)\n",
        "            plt.tight_layout()\n",
        "\n",
        "            # Format text results\n",
        "            comparison_text = \"📊 **Model Comparison Results:**\\n\\n\"\n",
        "            for model_name, results in all_results.items():\n",
        "                comparison_text += f\"**{model_name}:**\\n\"\n",
        "                for label, score in results.items():\n",
        "                    emoji = \"🚨\" if score > 0.5 else \"✅\"\n",
        "                    comparison_text += f\"  {emoji} {label.replace('_', ' ').title()}: {score:.3f}\\n\"\n",
        "                comparison_text += \"\\n\"\n",
        "\n",
        "            return comparison_text, fig\n",
        "\n",
        "        except Exception as e:\n",
        "            return f\"Error: {str(e)}\", None\n",
        "\n",
        "    # Create Gradio interface\n",
        "    with gr.Blocks(title=\"🛡️ Toxic Comment Detector\", theme=gr.themes.Soft()) as interface:\n",
        "        gr.Markdown(\"\"\"\n",
        "        # 🛡️ Toxic Comment Detector\n",
        "\n",
        "        This app uses four different pre-trained models to detect toxicity in comments.\n",
        "        Enter your text below and choose a model to get predictions, or compare all models at once!\n",
        "        \"\"\")\n",
        "\n",
        "        with gr.Tab(\"Single Model Prediction\"):\n",
        "            with gr.Row():\n",
        "                with gr.Column():\n",
        "                    text_input = gr.Textbox(\n",
        "                        label=\"Enter comment to analyze\",\n",
        "                        placeholder=\"Type your comment here...\",\n",
        "                        lines=3\n",
        "                    )\n",
        "                    model_dropdown = gr.Dropdown(\n",
        "                        choices=list(detector.models.keys()),\n",
        "                        label=\"Select Model\",\n",
        "                        value=list(detector.models.keys())[0] if detector.models else None\n",
        "                    )\n",
        "                    predict_btn = gr.Button(\"🔍 Analyze Toxicity\", variant=\"primary\")\n",
        "\n",
        "                with gr.Column():\n",
        "                    single_output = gr.Markdown(label=\"Results\")\n",
        "\n",
        "            predict_btn.click(\n",
        "                predict_toxicity,\n",
        "                inputs=[text_input, model_dropdown],\n",
        "                outputs=single_output\n",
        "            )\n",
        "\n",
        "        with gr.Tab(\"Compare All Models\"):\n",
        "            with gr.Row():\n",
        "                with gr.Column():\n",
        "                    compare_text_input = gr.Textbox(\n",
        "                        label=\"Enter comment to analyze\",\n",
        "                        placeholder=\"Type your comment here...\",\n",
        "                        lines=3\n",
        "                    )\n",
        "                    compare_btn = gr.Button(\"📊 Compare All Models\", variant=\"primary\")\n",
        "\n",
        "                with gr.Column():\n",
        "                    compare_output = gr.Markdown(label=\"Comparison Results\")\n",
        "\n",
        "            compare_plot = gr.Plot(label=\"Visual Comparison\")\n",
        "\n",
        "            compare_btn.click(\n",
        "                compare_models,\n",
        "                inputs=compare_text_input,\n",
        "                outputs=[compare_output, compare_plot]\n",
        "            )\n",
        "\n",
        "        gr.Markdown(\"\"\"\n",
        "        ---\n",
        "        ### 📝 Model Information:\n",
        "        - **DistilBERT**: Lightweight and fast, good for real-time applications\n",
        "        - **RoBERTa**: Robust and accurate, optimized training approach\n",
        "        - **ALBERT**: Parameter-efficient, good balance of speed and accuracy\n",
        "        - **ELECTRA-Small**: Very lightweight and fast, pre-trained with a novel discriminator approach\n",
        "\n",
        "        ### 🏷️ Labels Explained:\n",
        "        - **Toxic**: General toxicity\n",
        "        - **Severe Toxic**: Extremely toxic content\n",
        "        - **Obscene**: Obscene language\n",
        "        - **Threat**: Threatening language\n",
        "        - **Insult**: Insulting content\n",
        "        - **Identity Hate**: Hate speech targeting identity groups\n",
        "        \"\"\")\n",
        "\n",
        "    return interface"
      ],
      "metadata": {
        "id": "lLLks7hJfKoE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train models\n",
        "detector, results=train_toxic_detector(df)"
      ],
      "metadata": {
        "id": "LGS6ndvPfae8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#lauch gradio interface\n",
        "interface=create_gradio_interface(detector)\n",
        "interface.launch()"
      ],
      "metadata": {
        "id": "vCfISz0bKF9b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#this is to run instantly, no need to retrain the models again\n",
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
        "\n",
        "# Rebuild detector instance\n",
        "detector = ToxicCommentDetector()\n",
        "\n",
        "# List of saved models\n",
        "model_names = [\"DistilBERT\", \"RoBERTa\", \"ALBERT\", \"electra-small\"]\n",
        "\n",
        "# Load models from Drive\n",
        "for model_name in model_names:\n",
        "    try:\n",
        "        model_path = f\"/content/drive/MyDrive/toxic comment detector/{model_name}\"\n",
        "        model = AutoModelForSequenceClassification.from_pretrained(model_path, num_labels=len(detector.label_columns))\n",
        "        tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "        detector.models[model_name] = model\n",
        "        detector.tokenizers[model_name] = tokenizer\n",
        "        print(f\"✅ Loaded {model_name}\")\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Failed to load {model_name}: {e}\")\n",
        "\n",
        "# Launch Gradio UI\n",
        "gr_interface = create_gradio_interface(detector)\n",
        "gr_interface.launch()"
      ],
      "metadata": {
        "id": "4v1hlfA0Kbmq"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}